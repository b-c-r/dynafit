% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scan_gen_fr_parms.R
\name{scan_gen_fr_parms}
\alias{scan_gen_fr_parms}
\title{scan_gen_fr_parms: scans for reasonable starting parameters before fitting}
\usage{
scan_gen_fr_parms(
  n_eaten,
  n_initial,
  p,
  t_end,
  t_start = 0,
  t_length = 1000,
  f_max_range_log10,
  n_half_range_log10,
  q_range,
  penalty = 1000,
  q_low = 0,
  q_up = 1,
  no_lhs_samples = 1000,
  use_parallel_computing = FALSE,
  max_no_threads = 1,
  force_all_threads = FALSE
)
}
\arguments{
\item{n_eaten}{integer (or float); the prey items that were eaten throughout
the experimental trial. A vector.}

\item{n_initial}{integer (or float); the initial prey density. A vector of
the same length as n_eaten.}

\item{p}{The predator density. A single value}

\item{t_end}{integer or float; the time were the feeding ends. A single
value; default = 1 (e.g. 1 day).}

\item{t_start}{integer or float; the time were the feeding starts. A single
value; default = 0.}

\item{t_length}{integer or float; the number of time steps that should be
generated. The more time steps, the more precise the simulation. A single
value; default = 1000.}

\item{f_max_range_log10}{float; a range (2 values) of the log10 of the
maximum feeding rate.}

\item{n_half_range_log10}{float; a range (2 values) of the log10 of the half
saturation density.}

\item{q_range}{float; shape parameter, a range (2 values). A strict type II
functional has q = 0, a strict type III functional response has q = 1.
The values should match the values q_low and q_up below.
Default is c(0,1).}

\item{penalty}{a penalty that is added to the nll if the value of q is below
q_low or above q_up. The default= 1000. Equation:
if(q < q_low) nll + penalty*(q-q_low)^2
if(q > q_up) nll + penalty*(q-q_up)^2}

\item{q_low}{lower soft boundary of q, default = 0 (Type II FR).}

\item{q_up}{upper soft boundary of q, default = 1 (Type III FR).}

\item{no_lhs_samples}{a single integer value; the number of random latin
hypercube samplings. Default = 1000.}

\item{use_parallel_computing}{Unleash the power of your computer by allow for
parallel computing. Default is FALSE.}

\item{max_no_threads}{Only used if \code{use_parallel_computing} is TRUE. The
number of threads that should be used for parallel computing. Don't use
too many cores and do not overload your system. Default = 1.}

\item{force_all_threads}{Would you like to force the function to use the
maximum number of threads you defined in \code{max_no_threads}. If FALSE, the
functions tries to find a sweet spot of threads that depend on
\code{no_lhs_samples}. E.g., if you define to use 16 threads, and 1000 samples
should be taken it only uses 10 to get an even use of threads.}
}
\value{
Returns a data frame with a single row of parameter values.
}
\description{
\code{scan_gen_fr_parms} creates Latin hypercube samples for the
functional response parameters in a reasonable range and calculates the
according negative log-likelihood values. It returns the parameter values
with the lowest negative log likelihood of these samples. Non-linear
maximum likelihood fitting procedures require starting parameters,
generally based on an educated guess (e.g., Bolker 2008). Moreover,
these fits may end up in local best fits, and users should re-fit the
data using different starting parameters (Bolker 2008). To overcome
manually eyeballing as well as re-shuffling the starting parameters,
Jager and Ashauer (2018) suggested creating samples in a reasonable
parameter range using and choosing the starting parameters (from the
lowest nll value) from these samples. To reduce the number of required
samples by keeping the variance of parameter values as wide as possible,
it is recommended to use Latin hypercube sampling. \code{scan_gen_fr_parms}
requires the lhs package (Carnell 2024). See also the description of
\code{calc_gen_fr_nll} for further information.
}
\examples{


fr_data <- data_vucic_pestic_et_al_2010_j_anim_ecol

# Compute the results sequentially:

time_seq <- system.time({
  results_seq <- scan_gen_fr_parms(
    n_eaten = fr_data$n_eaten,
    n_initial = fr_data$n_initial,
    p = rep(1, nrow(fr_data)),
    t_end = rep(1, nrow(fr_data)),
    f_max_range_log10 = log10(c(1, max(fr_data$n_eaten))),
    n_half_range_log10 = log10(c(1, max(fr_data$n_initial))),
    q_range = c(0, 1),
    no_lhs_samples = 100
  )
})[[3]]

# the results:
results_seq


time_par <- system.time({
  results_par <- scan_gen_fr_parms(
    n_eaten = fr_data$n_eaten,
    n_initial = fr_data$n_initial,
    p = rep(1, nrow(fr_data)),
    t_end = rep(1, nrow(fr_data)),
    f_max_range_log10 = log10(c(1, max(fr_data$n_eaten))),
    n_half_range_log10 = log10(c(1, max(fr_data$n_initial))),
    q_range = c(0, 1),
    no_lhs_samples = 100,
    use_parallel_computing = TRUE,
    max_no_threads = 2
  )
})[[3]]

# the results:
results_par

# compare the time required:
time_seq
time_par

}
\references{
Bolker (2008) Ecological models and data in R, Princeton
University Press, Princeton, New Jersey.
https://math.mcmaster.ca/~bolker/emdbook/index.html

Carnell (2024) lhs: latin hypercube samples. Version 1.2.0.
https://CRAN.R-project.org/package=lhs

Jager and Ashauer (2018) Modelling survival under chemical stress
Leanpub. https://leanpub.com/guts_book
}
